{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the gist of top 2 stories from the US News website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the required packages\n",
    "1. Beautiful Soup from bs4 for web scraping\n",
    "2. get from requests for simulating web requests\n",
    "3. nltk for natural language processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the parameters for web request, namely website url and headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the websiteto be scraped\n",
    "url = \"https://www.usnews.com\"\n",
    "# Adding user agent as Mozilla to make the server believe that the request came from a browser\n",
    "user_agent = 'Mozilla/5.0'\n",
    "# Adding the user agent to the request header\n",
    "headers = {'User-Agent': user_agent}\n",
    "# Requesting the usnews website acess to the server and storing the response\n",
    "res = get(url, headers = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the response and storing the resulting html\n",
    "data = BeautifulSoup(res.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For simplification, I have used the class name of the left tab to extract the top 2 stories. This might need an update based on the website changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the class name of the left side tab, getting the corresponding html code for the top 2 stories\n",
    "result = data.find(class_ = \"ArmRestTopStories__Part-s13c9i18-1 joBuNB Box-s1krs5yn-0 bFmVmh\")\n",
    "# Getting the html code for the headings of top 2 stories using the h3 tag\n",
    "heading = result.findAll(\"h3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_url = []\n",
    "# Getting the link for the top 2 stories by using the href content from \"a\" tag and making a list\n",
    "for i in range(len(heading)):\n",
    "    story_url.append(heading[i].find(\"a\").get(\"href\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request for the actual news webpage and extract a gist of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gist(url):\n",
    "    # Creating a placeholder to store the final result, which is the first 3 sentences\n",
    "    final_res = \"\"\n",
    "    # Requesting the top story website acess to the server and storing the response\n",
    "    response1 = get(url, headers = headers)\n",
    "    # Parsing the response and storing the resulting html\n",
    "    data1 = BeautifulSoup(response1.text, \"html.parser\")\n",
    "    # Scraping the header of the 2nd top story using the \"h1\" tag and storing it in the result\n",
    "    final_res = final_res + \" \" + data1.find('h1').get_text()\n",
    "    # Scraping the sub-header of the 2nd top story using the \"h2\" tag and storing it in the result\n",
    "    final_res = final_res + \" \" + data1.find('h2').get_text()\n",
    "    # Using the class name of the content body, getting the corresponding html code\n",
    "    content = data1.find(class_ = \"ArticleBody__ArticleBox-s4gdqwu-2 dOjcJJ Box-s1krs5yn-0 ewBkVU\")\n",
    "    # Getting the first 4 paragraphs from the content using the \"p\" tag without any class attribute (to remove the external links)\n",
    "    res1 = content.findAll(\"p\", class_ = \"\", limit = 4)\n",
    "    # Concatenating the contents of the first 4 paragraphs with spaces between them (as the first 3 lines would be within max of 4 paragraphs)\n",
    "    result = res1[0].get_text() + \" \" + res1[1].get_text() + \" \" + res1[2].get_text() + \" \" + res1[3].get_text()\n",
    "    # Using the sentence tokenizer from the nltk package, splitting the contents into sentences.\n",
    "    sentences = nltk.sent_tokenize(result)\n",
    "    # Looping over the tokenized output from 0 - 2, to get the first 3 data\n",
    "    for i in range(5):\n",
    "        # Concatenating each new line to the placeholder result variable\n",
    "        final_res = final_res + \" \" + sentences[i]\n",
    "    return final_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story 0 :  Stay-At-Home Order Issued in Delaware Starting Tuesday Delaware Gov. John Carney has issued a stay-at-home order taking effect on Tuesday that closes non-essential businesses to attempt to blunt the intensity of the spread of the new coronavirus. WILMINGTON, Del. (AP) — Delaware Gov. John Carney on Sunday issued a stay-at-home order, closing \"non-essential\" businesses to attempt to blunt the intensity of the spread of the new coronavirus. Carney's emergency declaration takes effect at 8 a.m. Tuesday. Under the order, Delaware's 975,000 residents who otherwise don't work at the exempted businesses will be allowed only to leave their homes to get groceries or a prescription or see a doctor.\n",
      "\n",
      "Story 1 :  Rand Paul Becomes First Senator to Test Positive for Coronavirus The Kentucky Republican said he’s asymptomatic and will return to the Senate after his quarantine period. Republican Sen. Rand Paul of Kentucky announced Sunday that he has tested positive for the coronavirus, becoming the first member of the Senate to contract the highly contagious virus. Paul's Senate office tweeted that the senator isn't experiencing any symptoms and is \"feeling fine,\" but was tested for COVID-19, the disease caused by the coronavirus, since members of Congress travel frequently. Paul will remain in quarantine and continue to work remotely and return to the Senate once that period ends. \"Senator Rand Paul has tested positive for COVID-19. He is feeling fine and is in quarantine,\" his office tweeted Sunday afternoon.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the gist of the top 2 sotries\n",
    "for i in range(len(story_url)):\n",
    "    print(\"Story {0} : {1}\\n\".format(i, get_gist(story_url[i])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
